global:
  default_inherits: default

tools:
  default:
    cores: 2
    mem: 8
    env: {}
    scheduling:
      require: []
      prefer:
          general
      accept:
      reject:
          offline
    rules: []
    rank: |
      import requests
      import json
      import pathlib
      from ruamel.yaml import YAML
      from galaxy import model
      from sqlalchemy import select, func
      from datetime import datetime, timedelta

      sa_session = app.model.context

      # NOTE: currently object store info is stored in a yaml
      objectstore_loc_path = "tests/fixtures/object_store_locations.yml"
      dataset_attributes = helpers.get_dataset_attributes(job.input_datasets)

      yaml=YAML(typ='safe')
      objectstore_file = pathlib.Path(objectstore_loc_path)
      objectstore_dict = yaml.load(objectstore_file)

      # URL of the FastAPI application
      api_url = "http://localhost:8000/process_destinations"

      subquery_queued = select(
            model.JobStateHistory.job_id,
            func.min(model.JobStateHistory.create_time).label('create_time')
        ).where(
            model.JobStateHistory.state == 'queued'
        ).group_by(
            model.JobStateHistory.job_id
        ).alias('subquery_queued')

      subquery_running = select(
            model.JobStateHistory.job_id,
            func.min(model.JobStateHistory.create_time).label('create_time')
        ).where(
            model.JobStateHistory.state == 'running'
        ).group_by(
            model.JobStateHistory.job_id
        ).alias('subquery_running')

      subquery_finished = select(
            model.JobStateHistory.job_id,
            func.min(model.JobStateHistory.create_time).label('create_time')
        ).where(
            model.JobStateHistory.state == 'ok'
        ).group_by(
            model.JobStateHistory.job_id
        ).alias('subquery_finished')

      filter_after = datetime.now() - timedelta(days=30)

      subquery_job = select(
            model.Job.id, model.Job.destination_id, model.Job.tool_id
        ).where(
            func.lower(model.Job.tool_id).like(func.lower(job.tool_id)),
            model.Job.create_time > filter_after
        ).alias('subquery_job')

      subquery_destination = select(
          subquery_queued.c.job_id,
          subquery_queued.c.create_time.label('queued_time'),
          subquery_running.c.create_time.label('running_time'),
          subquery_finished.c.create_time.label('finished_time'),
          (subquery_running.c.create_time - subquery_queued.c.create_time).label('queue_time'),
          (subquery_finished.c.create_time - subquery_running.c.create_time).label('run_time')
      ).select_from(
          subquery_queued.join(
              subquery_running,
              subquery_queued.c.job_id == subquery_running.c.job_id
            ).join(
              subquery_finished,
              subquery_queued.c.job_id == subquery_finished.c.job_id,
              isouter=True
            )
      )

      final_query = select(
        subquery_job.c.destination_id,
        subquery_job.c.tool_id,
        func.count(subquery_job.c.id),
        func.avg(subquery_destination.c.queue_time).label('avg_queue_time'),
        func.min(subquery_destination.c.queue_time).label('min_queue_time'),
        func.percentile_cont(0.50).within_group(subquery_destination.c.queue_time.asc()).label('median_queue_time'),
        func.percentile_cont(0.95).within_group(subquery_destination.c.queue_time.asc()).label('perc_95_queue_time'),
        func.percentile_cont(0.99).within_group(subquery_destination.c.queue_time.asc()).label('perc_99_queue_time'),
        func.max(subquery_destination.c.queue_time).label('max_queue_time'),
        func.avg(subquery_destination.c.run_time).label('avg_run_time'),
        func.min(subquery_destination.c.run_time).label('min_run_time'),
        func.percentile_cont(0.50).within_group(subquery_destination.c.run_time.asc()).label('median_run_time'),
        func.percentile_cont(0.95).within_group(subquery_destination.c.run_time.asc()).label('perc_95_run_time'),
        func.percentile_cont(0.99).within_group(subquery_destination.c.run_time.asc()).label('perc_99_run_time'),
        func.max(subquery_destination.c.run_time).label('max_run_time')
      ).select_from(
        subquery_destination
      ).join(
        subquery_job,
        subquery_destination.c.job_id == subquery_job.c.id
      ).group_by(
        subquery_job.c.destination_id, subquery_job.c.tool_id
      ).order_by(
        subquery_job.c.destination_id
      )

      results = sa_session.execute(final_query).all()

      # Format the destination data and identify the total number of queued jobs for each destination
      candidate_destinations_list = []
      for dest in candidate_destinations:
          dest_dict = dest.to_dict()
          dest_dict["queued_job_count"] = app.model.context.query(model.Job).filter(model.Job.state == "queued", model.Job.destination_id == dest.dest_name).count()
          for row in results:
              if dest.dest_name in row:
                  row_dict = dict(row)
                  for key, value in row_dict.items():
                    if isinstance(value, timedelta):
                        dest_dict[key] = value.total_seconds()
                    else:
                        dest_dict[key] = value

          candidate_destinations_list.append(dest_dict)


      input_data = {
        "destinations": candidate_destinations_list,
        "objectstores": objectstore_dict,
        "dataset_attributes": dataset_attributes
      }

      # Send a POST request to the API endpoint
      response = requests.post(api_url, json=input_data)

      # Check if the request was successful (status code 200)
      if response.status_code == 200:
          result = response.json()
      else:
          print(f"Request failed with status code {response.status_code}: {response.text}")

      final_destinations = sorted(candidate_destinations, key=lambda obj: result["sorted_destinations"].index(str(obj.id)))

      final_destinations

  trinity:
    cores: 2
    mem: cores * 4
    env: {}
    scheduling:
      require: []
      prefer:
        - pulsar
      accept:
      reject:
        - offline

roles:
  ga_admins:
    scheduling:
      require:
        []


destinations:
  pulsar_italy:
    runner: general_pulsar_1
    max_accepted_cores: 8
    max_accepted_mem: 32
    scheduling:
      accept:
        - general
      require:
        - pulsar
    context:
      latitude: 50.0689816
      longitude: 19.9070188
  slurm_poland:
    runner: slurm
    max_accepted_cores: 16
    max_accepted_mem: 64
    scheduling:
      accept:
        - slurm
    context:
      latitude: 51.9189046
      longitude: 19.1343786
  condor_belgium:
    runner: condor
    max_accepted_cores: 16
    max_accepted_mem: 64
    scheduling:
      accept:
        - condor
    context:
      latitude: 50.5010789
      longitude: 4.4764595
  slurm_germany:
    runner: slurm
    max_accepted_cores: 16
    max_accepted_mem: 64
    scheduling:
      accept:
        - slurm
    context:
      latitude: 51.1642292
      longitude: 10.4541192
  condor_france:
    runner: condor
    max_accepted_cores: 16
    max_accepted_mem: 64
    scheduling:
      accept:
        - condor
    context:
      latitude: 46.71109
      longitude: 1.7191036
  pulsar_australia:
    runner: general_pulsar_1
    max_accepted_cores: 8
    max_accepted_mem: 32
    scheduling:
      accept:
        - general
      require:
        - pulsar
    context:
      latitude: -26.4390917
      longitude: 133.281323
